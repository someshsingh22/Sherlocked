{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom collections import Counter\nimport os\nimport re\nfrom argparse import Namespace\nimport time\nfrom tqdm import tqdm_notebook, tnrange\nimport seaborn as sns\nfrom torch.optim.lr_scheduler import StepLR","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_time(function):\n    def inner(*args,**kwargs):\n        begin=time.time()\n        function(*args,**kwargs)\n        end=time.time()\n        print(\"This took {}s\".format(end-begin))\n    return inner\n\nclass Author:\n    def __init__(self,flags):\n        self.flags=flags\n        self.Data=Data(flags)\n        self.Brain=Brain(flags,self.Data.n_vocab)\n        self.Pen=Pen(flags,self.Data.vocab_to_int,self.Data.int_to_vocab)\n    def Train(self,epochs):\n        self.Brain.Train(epochs,self.Data,self.Pen)\n        \n\nclass Pen:\n    def __init__(self,flags,vocab_to_int,int_to_vocab):\n        self.flags=flags\n        self.vocab_to_int,self.int_to_vocab=vocab_to_int,int_to_vocab\n    \n    def write(self,Brain,words=\"Harry is\",temperature=0.5,length=70):\n        probs=[80-60*temperature,60-20*temperature,50,40+20*temperature,20+60*temperature]\n        probs=[prob/250 for prob in probs]\n\n        words=words.split()\n        Brain.eval()\n        state_h, state_c = Brain.zero_state(1)\n        state_h = state_h.to(self.flags.device)\n        state_c = state_c.to(self.flags.device)\n\n        for w in words:\n            ix = torch.tensor([[self.vocab_to_int[w]]]).to(self.flags.device)\n            output, (state_h, state_c) = Brain(ix, (state_h, state_c))\n            top_k=int(np.random.choice(np.arange(1,6),1,p=probs))\n\n        _, top_ix = torch.topk(output[0], k=top_k)\n        choices = top_ix.tolist()\n        choice = np.random.choice(choices[0])\n        words.append(self.int_to_vocab[choice])\n\n        for _ in range(length):\n            ix = torch.tensor([[choice]]).to(self.flags.device)\n            output, (state_h, state_c) = Brain(ix, (state_h, state_c))\n            top_k=int(np.random.choice(np.arange(1,6),1,p=probs))\n\n            _, top_ix = torch.topk(output[0], k=top_k)\n            choices = top_ix.tolist()\n            choice = np.random.choice(choices[0])\n            words.append(self.int_to_vocab[choice])\n    \n        prediction=' '.join(words)\n        print(prediction)\n        return prediction\n\n# Data Class\nclass Data :\n    def __init__(self,flags):\n        self.flags=flags\n    \n        # Pre Process Data\n        self.pre_process()\n    \n  # Prepare Data For Training\n    @calculate_time\n    def pre_process(self):\n        start=time.time()\n        # Read datat and split to words from files\n        text=open(self.flags.data_dir).read().split()\n        print(\"Dataset is of {} words\".format(len(text)))\n\n        # Create Frequency Dictionary\n        word_counts = Counter(text)\n        self.sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n\n        # Word2Vec Mapping\n        self.int_to_vocab = {k: w for k, w in enumerate(self.sorted_vocab)}\n        self.vocab_to_int = {w: k for k, w in self.int_to_vocab.items()}\n        self.n_vocab = len(self.int_to_vocab)\n\n        # Create Input-Output Data\n        int_text = [self.vocab_to_int[w] for w in text]\n        num_batches = int(len(int_text) / (self.flags.seq_size * self.flags.batch_size))\n        in_text = int_text[:num_batches * self.flags.batch_size * self.flags.seq_size]\n        out_text = np.zeros_like(in_text)\n        out_text[:-1] = in_text[1:]\n        out_text[-1] = in_text[0]\n        in_text = np.reshape(in_text, (self.flags.batch_size, -1))\n        out_text = np.reshape(out_text, (self.flags.batch_size, -1))\n        print(\"Data Preprocessing complete with {} words\".format(self.n_vocab))\n        self.in_text=in_text\n        self.out_text=out_text\n\n  # Create Input-Output Batch Generator \n    def get_batches(self):\n        num_batches = np.prod(self.in_text.shape) // (self.flags.seq_size * self.flags.batch_size)\n        for i in range(0, num_batches * self.flags.seq_size, self.flags.seq_size):\n            yield self.in_text[:, i:i+self.flags.seq_size], self.out_text[:, i:i+self.flags.seq_size]\n\nclass Brain(nn.Module):\n    def __init__(self,flags,n_vocab,):\n        super(Brain,self).__init__()\n        self.flags=flags\n        self.embedding= nn.Embedding(n_vocab, flags.embedding_size)\n        self.lstm=nn.LSTM(flags.embedding_size, flags.lstm_size, batch_first=True, num_layers=flags.num_layers, dropout=flags.dropout)\n        self.dense = nn.Linear(flags.lstm_size, n_vocab)\n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.flags.lr)\n        self.loss_value=0\n        self.to(flags.device)\n        self.plot_loss=[]\n        # gamma = decaying factor\n        self.scheduler = StepLR(self.optimizer, step_size=2, gamma=0.96)\n    \n  # Forward Pass\n    def forward(self, x, prev_state):\n        embed = self.embedding(x)\n        output, state = self.lstm(embed, prev_state)\n        logits = self.dense(output)\n        return logits, state\n\n  # ZeroState Init\n    def zero_state(self,batch_size):\n        return (torch.zeros(self.flags.num_layers, batch_size, self.flags.lstm_size),\n                torch.zeros(self.flags.num_layers, batch_size, self.flags.lstm_size))\n  \n  #Train Function\n    @calculate_time\n    def Train(self,epochs,Data,Pen):\n        self.train()\n        for epoch in tnrange(1,epochs+1,desc=\"Epoch Loop\"):\n            start=time.time()\n            batches=Data.get_batches()\n            state_h, state_c = self.zero_state(self.flags.batch_size)\n\n            # Transfer data to GPU\n            state_h = state_h.to(self.flags.device)\n            state_c = state_c.to(self.flags.device)\n            \n            for x, y in (batches):\n            #for x, y in (batches,desc=\"Batch Loop\",total=87,leave=False):\n\n                # Reset all gradients\n                self.optimizer.zero_grad()\n\n                # Transfer data to GPU\n                x = torch.tensor(x).to(self.flags.device)\n                y = torch.tensor(y).to(self.flags.device)\n\n                logits, (state_h, state_c) = self(x, (state_h, state_c))\n                self.loss = self.criterion(logits.transpose(1, 2), y)\n\n                state_h = state_h.detach()\n                state_c = state_c.detach()\n\n                self.loss_value = self.loss.item()\n\n                # Update the network's parameters\n                self.optimizer.step()\n                self.loss.backward()\n                _ = torch.nn.utils.clip_grad_norm_(self.parameters(), self.flags.gradients_norm)\n                #self.Optimizer.decay(self.loss)\n\n                self.optimizer.step()\n            callback='Loss: {} Time Taken : {}'.format(self.loss_value,time.time()-start)\n            self.scheduler.step()\n            print(callback)\n            self.plot_loss.append(self.loss_value)\n            if self.loss_value < 0.75 :\n                break\n            if epoch%10==0:\n                print(\"-\"*20,\"\\nEpoch {}:\".format(epoch))\n                Pen.write(self)\n                print(\"-\"*20+\"\\n\")\n                self.train()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outfile=\"\"\ndef prewrite(outfile,flags):\n    outfile+=(\"-\"*20+\"\\n\")\n    for key in flags.__dict__:\n        val=flags.__dict__[key]\n        if type(val) == int:\n            outfile+=(str(key)+\"\\n\")\n            outfile+=(str(val)+\"\\n\")\n    outfile+=(\"-\"*20+\"\\n\")\n    return outfile","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def commit_file(outfile,flags,epochs=3):\n    print(prewrite(outfile,flags))\n    Rowling=Author(flags)\n    Rowling.Train(epochs)\n    x=[i+1 for i in range(len(Rowling.Brain.plot_loss))]\n    sns.lineplot(x,Rowling.Brain.plot_loss)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_path=\"../input/repository/someshsingh22-Sherlocked-39b34b9/Dataset/Clean/{}.txt\"\nwrite_path=\"{}_Results.txt\"\nfile=\"HP_Stitched\"\nflags = Namespace(\n    data_dir=read_path.format(file),\n    batch_size=256,\n    seq_size=64,\n    embedding_size=256,\n    num_layers=2,\n    is_bidirectional=True,\n    lstm_size=512,\n    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n    write_dir=write_path.format(file),\n    lr=0.001,\n    dropout=0.2,\n    gradients_norm=5,\n)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flags.is_bidirectional=True\nflags.lstm_size=512\nflags.num_layers=2\ncommit_file(outfile,flags,100)","execution_count":6,"outputs":[{"output_type":"stream","text":"--------------------\nbatch_size\n300\nseq_size\n64\nembedding_size\n256\nnum_layers\n2\nlstm_size\n512\ngradients_norm\n5\n--------------------\n\nDataset is of 1431857 words\nData Preprocessing complete with 24985 words\nThis took 0.9699447154998779s\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, description='Epoch Loop', style=ProgressStyle(description_width='initial')â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff0981ec91174e79b2003a8042c529f2"}},"metadata":{}},{"output_type":"stream","text":"Loss: 6.463463306427002 Time Taken : 40.07043766975403\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-43a32a307d1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcommit_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-0255a194b8be>\u001b[0m in \u001b[0;36mcommit_file\u001b[0;34m(outfile, flags, epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mRowling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAuthor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mRowling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRowling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRowling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-d541943fa391>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_to_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_to_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-d541943fa391>\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbegin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This took {}s\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-d541943fa391>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, epochs, Data, Pen)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;31m# Update the network's parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;31m#self.Optimizer.decay(self.loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"flags.is_bidirectional=True\nflags.lstm_size=1024\nflags.num_layers=1\ncommit_file(outfile,flags,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flags.is_bidirectional=False\nflags.lstm_size=512\nflags.num_layers=2\ncommit_file(outfile,flags,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flags.is_bidirectional=False\nflags.lstm_size=1024\nflags.num_layers=1\ncommit_file(outfile,flags,100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}